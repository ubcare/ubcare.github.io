---
layout: post
title: "데이터 분석? 그거 뭔데, 어떻게 하는건데 !"
date: 2021-06-28
author: 정준호
categories: Post
cover: "/assets/bigdata.jpg"
---

# Data Anaysis Process

데이터 분석, 데이터 마이닝, AI, 머신러닝, 딥러닝 등 데이터를 기반으로 학습하고 적용하여 인사이트를 추출하는 일련의 과정들이, 현 시대에서 누구나 한 번 쯤은 들어보았을 단어가 되었습니다. 이 단어들은 어떠한 프로세스를 대표하는 단어가 되었고, 각각 조금씩의 차이는 있겠지만 큰 흐름 안에서 같은 프로세스를 지향하고 있습니다. 이것만이 정답이라고 할 수는 없겠지만, 데이터를 분석하는 프로세스를 간단하게 정리해 보려합니다. 이 글에서는 **'데이터를 기반으로 학습하고 적용하는 일련의 과정'**을 **데이터 분석**이라고 통칭해서 진행하겠습니다.

![](/assets/posting/20210628/D.png)<center> [데이터 분석 프로세스]</center>
<br>
데이터 분석의 과정을 개괄적으로 도식화한 그림입니다. 더 세분화하게 나눌수도 있고, 축약할 수도 있으며 새로운 꼭지를 추가하기도, 이동하기도 할 수 있으나 흐름의 대세는 동일 할 것입니다. 순서에 따라 하나씩 살펴보겠습니다. 

---
<br>

## 문제 정의 & 모델 정의

 가장 중요하지만 가장 어려운 단계입니다. 분석의 대상이되고 분석의 목적인 문제 정의가 제대로 설정되지 않으면 분석 목표가 불분명해집니다. 비지니스적 요구사항을 해석하고 구체화하여 데이터 엔지니어와 협업을 통해 분석을 준비하여야 합니다. 

 어떤 프로젝트건 마찬가지겠지만, 프로젝트를 어떻게 설계했느냐가 전체 프로젝트의 성패를 좌우하기도 합니다. 그렇기에 무엇을 위해 분석을 진행하는지, 어떤 데이터를 가지고있는지, 어떤 데이터가 필요한지, 어떤 방향성으로 분석할 것인지 정의하는 것은 아무리 강조해도 지나치지 않습니다.

문제 정의를 어느 정도 고민했느냐가 프로젝트의 성패를 가릅니다.
<br>
![](/assets/posting/20210628/D1.png)<center>[분석 목적에 따른 방법론]</center><br>

![](/assets/posting/20210628/D2.png)<center>[분석 방법론에 따른 머신러닝 알고리즘]</center>
<br>
 문제 정의 이후에 개괄적으로 어떤 분석방법을 사용해야 할 지 방향성을 잡을 수 있습니다. 분석의 목적에 따라 지도학습/비지도학습으로 나눌 수 있고, 각 학습 방법에 따라 비지도-군집/차원축소/추천, 지도-분류/회귀 등 분석방법의 방향성을 정합니다. 어떤 분석방법을 사용할지 결정하였으면 이에 해당하는 머신러닝 모델까지 범위가 특정됩니다. 

 각 모델의 특성에 따라 데이터를 처리가 달라질 수 있습니다. 그러나 여기서 정한 모델을 무조건 사용해야 하는것은 아닙니다. 바로 뒤에 나오게 될 EDA 탐색을 통해서 새로운 방향성을 발견하게 되면 상황에 맞게 모델은 변경 가능하게 됩니다.

---
<br>

## 데이터 수집 및 가공

### 데이터 수집

 데이터 분석을 진행하기 위해서는 데이터를 파악하고 수집해야 합니다. 소유하고 있는 데이터와 분석을 위해 수집해야 하는 데이터를 파악해야 합니다. 내부에 소유하고 있는 데이터라고 모든 데이터를 사용하는 것은 아닙니다. 기본적인 관점에서 필요한 데이터를 선별해서 수집합니다. 외부의 데이터 중에서 필요한 데이터는 수집 가능성여부를 파악하고 어떻게 수집할 것인지 계획해야 합니다. 
<br>

### 탐색적 데이터 분석(Explorary Data Analysis)

 수집한 데이터가 어떻게 구성되어있는지 파악하는 작업입니다. 정형데이터인지 비정형데이터인지, 데이터 사이즈는 어떻게 되는지, 데이터의 구조는 어떻게 구성되었는지, 데이터 속성과 분포는 어떤지, 결측값과 이상치는 어느정도인지 파악하고 탐색하는 작업입니다. 주로 기술통계량, Boxplot, Scatter plot, Histogram 등 통계량과 그래프를 통해 탐색합니다.

---

- 데이터 속성 및 분포
- 데이터 구조

- 정형/비정형
- 기술통계량

- 데이터 사이즈
- 결측값/이상치

---

 탐색적 데이터 분석은 이후에 있을 데이터 전처리 후에도 진행됩니다. 앞단에서의 EDA가 데이터의 구조파악에 목적을 두었다면, 데이터 전처리 후에는 조금더 분석 모델링에 초점을 두고 EDA를 진행합니다. 가령 독립변수들간의 관계라던가, 종속변수에 영향을 미치는 독립변수 파악 등 피쳐 엔지니어링 없이 변수들 자체의 관계를 파악하는데 사용됩니다.
<br>

### 데이터 전처리(Data Preprocessing)

 탐색적 데이터 분석을 통해 데이터 핸들링 방향을 파악했습니다. 데이터 전처리를 통해 데이터 셋을 만들어야 합니다. 결측치를 어떻게 처리할 지(대체, 삭제) 결정하고, 이상치를 다루는 방법을 고민합니다. 변수간의 단위와 분포가 다르다면 Scaling 작업을 통해 정규화 합니다. 변수 하나하나의 타입도 머신러닝 모델에 맞게 변경해 주어야 합니다. 

---
![](/assets/posting/20210628/D3.png)<center>[결측치 처리 예시 - 평균 대체]</center>
<br>
![](/assets/posting/20210628/D4.png)<center>[이상치 예시]</center>
<br>
![](/assets/posting/20210628/D5.png)<center>[정규화 예시]</center>
<br>

---

데이터 셋을 제대로 만드는 것이 모델의 정확도를 높이는 가장 좋은 방법입니다. 뒤에 이어지는 Feature Engineering 부분과 함께 데이터 핸들링 영역에서 가장 중요한 부분중 하나입니다. 
<br>

### Feature Engineering

 Feature Engineering 과정은 더 나은 모델 알고리즘 성능을 위해 Raw Data로 부터 Feature를 만들거나 재구성하는 과정입니다. 변수들간의 결합으로 새로운 피쳐가 나오기도하고, 비슷한 변수들로 인해 모델이 복잡해지는 것을 방지하기 위해, 차원축소를 통해 변수를 대표하는 피쳐를 만들어 대체하기도 합니다. 또 독립변수간의 상관성이 발견되면 변수를 제거하기도 하면서 모델에 사용할 Feature를 특정해 가는 작업입니다. 대부분의 머신러닝 모델은 연속형 변수를 인풋값으로 받습니다. 범주형 타입의 변수가 있을때는 모델에 학습 가능한 데이터의 형태로 변환해 주어야 하는데, 이런 작업도 Feature Engineering의 영역에 속합니다.

---

- Feature Extrantion : 주어진 Feature를 바탕으로 새로운 Feature를 만들어 내는 과정. Feature가 추가되기도, 축소되기도 한다.
- Feature Selection : 여러 Feature들 가운데 일부를 선택하는 것. 무의미한 Feature는 모델 예측력에 안좋은 영향을 미치므로 Feature를 잘 선택하는 것이 중요하다. 그러나 Feature와 예측값과의 관계를 특정할 수 없는 초기의 경우 보수적으로 선택해야 한다.
- Encoding : 데이터의 타입에 따라 모델에 맞는 Feature로 변환 작업이 필요합니다. 범주형 데이터를 더미화 하거나 산발적인 값을 Binning 할 때 사용합니다.
![](/assets/posting/20210628/D6.png)<center>[Feature Extraction - 차원축소 예시]</center>
<br>

![](/assets/posting/20210628/D7.png)<center>[Encoding - 더미화 예시]</center>
<br>

---
<br>

## 모델 구현

 분석 모델에 사용할 데이터 셋이 완성되었으면 실제 모델을 생성하고 학습시켜야 합니다. 우리에게 주어진 데이터셋은 한정되어 있으므로, 학습용 데이터(Train_Data), 검증용 데이터(Validation_Data), 테스트용 데이터(Test_Data) 셋(set) 으로 나누는 작업을 진행해야 합니다. 때에 따라서 학습용과 테스트용으로만 나누기도 합니다. 
![](/assets/posting/20210628/D8.png)<center>[Data Split Example]</center>
<br>

 학습용 데이터로 모델을 생성하고 검증용 데이터로 생성된 모델의 성능을 측정합니다. 모델의 성능을 높이기 위해 모델을 튜닝하기도 하고, Feature Engineering을 다시 진행하기도 하기도 합니다. Feature Engineering과 모델 생성 및 평가를 반복하면서 최적의 모델을 선정합니다. 

 알고리즘 모델의 종류에 따라 각자의 모델 평가 방법이 있는데, 가장 대표적인 방법으로는 예측 모델일 경우 RMSE, R-Squared를 사용하고 분류 모델일 경우 Confusion Matrix를 통한 Accuracy, ROC 등을 지표로 사용한다. 그렇게 선정된 모델에 테스트 데이터를 통해 모델의 최종 성능을 확인합니다. 

---
<br>

## 모델 적용

 최종 선택된 모델을 활용합니다. 기존의 데이터셋이 아닌, 새롭게 생성되는 데이터에 학습된 모델을 적용합니다.

 머신러닝 모델은 데이터를 기반으로 생성됩니다. 좋은 성능을 나타내는 모델이 한 번 만들어 졌다고 해도, 발생하는 데이터의 흐름이 바뀌게 되면 모델의 성능은 저하되게 됩니다. 시간이 지남에 따라 머신러닝 모델은 고도화작업, 또는 새로운 모델 생성 작업이 필요합니다. 

 한 번의 모델 생성으로 평생 최고의 성능을 보여준다면 좋겠지만, 우리가 마주한 현실을 그렇게 녹록치 않습니다. 끊임없이 모델을 업데이트하고 고도화 하면서 더 잘 동작할 수 있도록 사람의 관여가 필요합니다. 

---

<br>

## 마무리

 데이터 분석을 진행하는 프로세스를 개괄적으로 파악해보았습니다. 한 부분 부분이 워낙 방대한 양이기에 언급되지 않은 다양한 기술과 방법이 있지만, 데이터로부터 결과를 도출하는 일련의 과정은 대세의 흐름을 벗어나지 않을 것입니다. 

 사실 데이터 분석을 통해 모델을 만들어 낸 것이 우리의 삶을 드라마틱하게 바꾸지는 못할 것입니다. 영화에서 접한 것 같은 AI가, 모델링 하나 생성했다고 완성되지 않는다는 것입니다. 이러한 과도한 기대치를 버리고 접근하는 것에서 데이터 분석은 시작됩니다. 그럼에도 우리가 데이터를 통해 인사이트를 발견하고 모델링을 구현하는 것은, 우리가 알지 못했던 근거가 데이터에 숨겨져 있고, 그 근거가 우리 행동의 방향 설정을 도와주는 역할을 할 수 있기 때문입니다. 이 글로 인해 데이터에 숨겨진 정보를 찾는데 관심이 생기고, 정보를 찾는 절차에 대한 이해가 높아지길 바랍니다.